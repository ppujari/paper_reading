{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d371e7",
   "metadata": {
    "papermill": {
     "duration": 0.00788,
     "end_time": "2023-05-01T05:18:15.809444",
     "exception": false,
     "start_time": "2023-05-01T05:18:15.801564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "__Author__ = \"Pradeep Pujari\"  \n",
    "__Competition__ = \"Stable Diffusion - Image to Prompts April 2023\"   \n",
    "__Version__ = \"0 - Base line model\"  \n",
    "__Paper__ = \"BLIP-2 https://arxiv.org/abs/2301.12597\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf12695",
   "metadata": {
    "papermill": {
     "duration": 0.006494,
     "end_time": "2023-05-01T05:18:15.823252",
     "exception": false,
     "start_time": "2023-05-01T05:18:15.816758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Table Of Contents  \n",
    "1. Goal of the Competition  \n",
    "2. Install and Import dependendent packages  \n",
    "3. Config Setup \n",
    "4. Load BLIP2 Model  \n",
    "5. Submission Code\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972f860",
   "metadata": {
    "papermill": {
     "duration": 0.006316,
     "end_time": "2023-05-01T05:18:15.836177",
     "exception": false,
     "start_time": "2023-05-01T05:18:15.829861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Goal of the Competition  \n",
    "**The competition aims to create a model that can predict the text prompt given a generated image, instead of generating an image from a text prompt. The dataset contains various (prompt, image) pairs generated by Stable Diffusion 2.0, and the goal is to determine how reversible the latent relationship is.**\n",
    "\n",
    "**Context**  \n",
    "The popularity of text-to-image models has spurned an entire new field of prompt engineering. Part art and part unsettled science, ML practitioners and researchers are rapidly grappling with understanding the relationships between prompts and the images they generate. Is adding \"4k\" to a prompt the best way to make it more photographic? Do small perturbations in prompts lead to highly divergent images? How does the order of prompt keywords impact the resulting generated scene? This competition tasks you with creating a model that can reliably invert the diffusion process that generated to a given image.\n",
    "\n",
    "In order to calculate prompt similarity in a robust way—meaning that \"epic cat\" is scored as similar to \"majestic kitten\" in spite of character-level differences—you will submit embeddings of your predicted prompts. Whether you model the embeddings directly or first predict prompts and then convert to embeddings is up to you! Good luck, and may you create \"highly quality, sharp focus, intricate, detailed, in the style of unreal robust cross validation\" models herein.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc9186",
   "metadata": {
    "papermill": {
     "duration": 0.006398,
     "end_time": "2023-05-01T05:18:15.849265",
     "exception": false,
     "start_time": "2023-05-01T05:18:15.842867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install and Import dependendent packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee0546d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:18:15.864826Z",
     "iopub.status.busy": "2023-05-01T05:18:15.864031Z",
     "iopub.status.idle": "2023-05-01T05:18:15.870223Z",
     "shell.execute_reply": "2023-05-01T05:18:15.868870Z"
    },
    "papermill": {
     "duration": 0.016937,
     "end_time": "2023-05-01T05:18:15.872711",
     "exception": false,
     "start_time": "2023-05-01T05:18:15.855774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install blip\n",
    "#!pip list\n",
    "#!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35524401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:18:15.888963Z",
     "iopub.status.busy": "2023-05-01T05:18:15.887639Z",
     "iopub.status.idle": "2023-05-01T05:18:24.567570Z",
     "shell.execute_reply": "2023-05-01T05:18:24.565953Z"
    },
    "papermill": {
     "duration": 8.690999,
     "end_time": "2023-05-01T05:18:24.570502",
     "exception": false,
     "start_time": "2023-05-01T05:18:15.879503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import requests\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoProcessor, BlipForConditionalGeneration\n",
    "#from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/sentence-transformers-222/sentence-transformers')\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "#from IPython.display import clear_output\n",
    "#from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf143f3",
   "metadata": {
    "papermill": {
     "duration": 0.006321,
     "end_time": "2023-05-01T05:18:24.583513",
     "exception": false,
     "start_time": "2023-05-01T05:18:24.577192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f02ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:18:24.599680Z",
     "iopub.status.busy": "2023-05-01T05:18:24.598930Z",
     "iopub.status.idle": "2023-05-01T05:18:24.608459Z",
     "shell.execute_reply": "2023-05-01T05:18:24.607394Z"
    },
    "papermill": {
     "duration": 0.020968,
     "end_time": "2023-05-01T05:18:24.611143",
     "exception": false,
     "start_time": "2023-05-01T05:18:24.590175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comp_path = Path('/kaggle/input/stable-diffusion-image-to-prompts/')\n",
    "folder_path = \"/kaggle/working/\" \n",
    "image_files=[]\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/stable-diffusion-image-to-prompts/images/'):\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input/900k-diffusion-prompts-dataset/features/'):\n",
    "    for filename in sorted(filenames):\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        image_files.append(os.path.join(dirname, filename))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134c4dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:18:24.627089Z",
     "iopub.status.busy": "2023-05-01T05:18:24.626380Z",
     "iopub.status.idle": "2023-05-01T05:18:24.639054Z",
     "shell.execute_reply": "2023-05-01T05:18:24.637933Z"
    },
    "papermill": {
     "duration": 0.023905,
     "end_time": "2023-05-01T05:18:24.641795",
     "exception": false,
     "start_time": "2023-05-01T05:18:24.617890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = sorted(os.listdir(comp_path / 'images'))\n",
    "imgIds = [i.split('.')[0] for i in images]\n",
    "\n",
    "EMBEDDING_LENGTH = 384\n",
    "eIds = list(range(EMBEDDING_LENGTH))\n",
    "\n",
    "imgId_eId = [\n",
    "    '_'.join(map(str, i)) for i in zip(\n",
    "        np.repeat(imgIds, EMBEDDING_LENGTH),\n",
    "        np.tile(range(EMBEDDING_LENGTH), len(imgIds)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ddf41",
   "metadata": {
    "papermill": {
     "duration": 0.006273,
     "end_time": "2023-05-01T05:18:24.654635",
     "exception": false,
     "start_time": "2023-05-01T05:18:24.648362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The Sample Submission contains correct embeddings (for the example images)\n",
    "The sample_submission.csv file on the Data page has the correct imbeddings for the prompts listed in the prompts.csv file. This is so you can test whether you are calculating embeddings correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a942f678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:18:24.671080Z",
     "iopub.status.busy": "2023-05-01T05:18:24.670340Z",
     "iopub.status.idle": "2023-05-01T05:18:26.915187Z",
     "shell.execute_reply": "2023-05-01T05:18:26.913702Z"
    },
    "papermill": {
     "duration": 2.256877,
     "end_time": "2023-05-01T05:18:26.918126",
     "exception": false,
     "start_time": "2023-05-01T05:18:24.661249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "st_model = SentenceTransformer('/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef095b",
   "metadata": {
    "papermill": {
     "duration": 0.00624,
     "end_time": "2023-05-01T05:18:26.931060",
     "exception": false,
     "start_time": "2023-05-01T05:18:26.924820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the embedding model all-MiniLM-L6-v2\n",
    "We're loading this from the attached dataset, which you will also need to attach to your notebooks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d636c1",
   "metadata": {
    "papermill": {
     "duration": 0.006472,
     "end_time": "2023-05-01T05:18:26.944102",
     "exception": false,
     "start_time": "2023-05-01T05:18:26.937630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Stable Diffusion Process with BLIP2 - Here weights are pretrained compared to BLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37d7f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:18:26.959978Z",
     "iopub.status.busy": "2023-05-01T05:18:26.959555Z",
     "iopub.status.idle": "2023-05-01T05:18:58.628301Z",
     "shell.execute_reply": "2023-05-01T05:18:58.626770Z"
    },
    "papermill": {
     "duration": 31.689633,
     "end_time": "2023-05-01T05:18:58.640370",
     "exception": false,
     "start_time": "2023-05-01T05:18:26.950737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlipForConditionalGeneration(\n",
       "  (vision_model): BlipVisionModel(\n",
       "    (embeddings): BlipVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (encoder): BlipEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (12): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (13): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (14): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (15): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (16): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (17): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (18): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (19): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (20): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (21): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (22): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (23): BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (text_decoder): BlipTextLMHeadModel(\n",
       "    (bert): BlipTextModel(\n",
       "      (embeddings): BlipTextEmbeddings(\n",
       "        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): BlipTextEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BlipTextOnlyMLMHead(\n",
       "      (predictions): BlipTextLMPredictionHead(\n",
       "        (transform): BlipTextPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth'\n",
    "processor = AutoProcessor.from_pretrained(\"/kaggle/input/salesforceblip-image-caption\")\n",
    "\n",
    "#model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"/kaggle/input/salesforceblip-image-caption\")\n",
    "\n",
    "model.to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e632d3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:18:58.659194Z",
     "iopub.status.busy": "2023-05-01T05:18:58.657666Z",
     "iopub.status.idle": "2023-05-01T05:18:58.664463Z",
     "shell.execute_reply": "2023-05-01T05:18:58.663508Z"
    },
    "papermill": {
     "duration": 0.018769,
     "end_time": "2023-05-01T05:18:58.666953",
     "exception": false,
     "start_time": "2023-05-01T05:18:58.648184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_prompt(raw_image):\n",
    "    inputs = processor(raw_image, return_tensors=\"pt\").to(device)\n",
    "    out = model.generate(**inputs, max_new_tokens=32)\n",
    "    generated_prompt = processor.batch_decode(out, skip_special_tokens=True)[0].strip()\n",
    "    return generated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18fd8918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:18:58.686359Z",
     "iopub.status.busy": "2023-05-01T05:18:58.685413Z",
     "iopub.status.idle": "2023-05-01T05:19:51.881954Z",
     "shell.execute_reply": "2023-05-01T05:19:51.880541Z"
    },
    "papermill": {
     "duration": 53.210124,
     "end_time": "2023-05-01T05:19:51.885013",
     "exception": false,
     "start_time": "2023-05-01T05:18:58.674889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prompts: 100%|██████████| 7/7 [00:53<00:00,  7.60s/it]\n"
     ]
    }
   ],
   "source": [
    "generated_prompts =[]\n",
    "\n",
    "for idx, file in enumerate(tqdm(image_files, desc='Generating prompts')):\n",
    "\n",
    "#    image = Image.open(file).convert('RGB')\n",
    "    image = Image.open(file)\n",
    "    #prompts=dict()\n",
    "    prompt = image_to_prompt(image)\n",
    "    #prompts['imageId']=file.split('/')[-1]\n",
    "    #prompts['prompt']=prompt\n",
    "    generated_prompts.append(prompt)\n",
    "    #print(file)\n",
    "    #print(prompt)\n",
    "    #thumb = image.copy()\n",
    "    #thumb.thumbnail([256, 256])\n",
    "    #display(thumb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d8913",
   "metadata": {
    "papermill": {
     "duration": 0.008119,
     "end_time": "2023-05-01T05:19:51.901744",
     "exception": false,
     "start_time": "2023-05-01T05:19:51.893625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculate prompt embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e159b42f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:51.921711Z",
     "iopub.status.busy": "2023-05-01T05:19:51.920106Z",
     "iopub.status.idle": "2023-05-01T05:19:51.925397Z",
     "shell.execute_reply": "2023-05-01T05:19:51.924482Z"
    },
    "papermill": {
     "duration": 0.017461,
     "end_time": "2023-05-01T05:19:51.927697",
     "exception": false,
     "start_time": "2023-05-01T05:19:51.910236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(generated_prompts)\n",
    "#new_generated_prompts = pd.DataFrame(generated_prompts).set_index(['imageId'])\n",
    "#new_generated_prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84cce30a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:51.947294Z",
     "iopub.status.busy": "2023-05-01T05:19:51.946544Z",
     "iopub.status.idle": "2023-05-01T05:19:52.039832Z",
     "shell.execute_reply": "2023-05-01T05:19:52.038469Z"
    },
    "papermill": {
     "duration": 0.106229,
     "end_time": "2023-05-01T05:19:52.042394",
     "exception": false,
     "start_time": "2023-05-01T05:19:51.936165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b7793b3d3c48a3b5dfe84eeed29b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "#encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "prompt_embeddings = st_model.encode(generated_prompts).flatten()\n",
    "submission = pd.DataFrame(\n",
    "                index=imgId_eId,\n",
    "                data=prompt_embeddings,\n",
    "                columns=['val']).rename_axis('imgId_eId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b86697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:52.062856Z",
     "iopub.status.busy": "2023-05-01T05:19:52.061642Z",
     "iopub.status.idle": "2023-05-01T05:19:52.089459Z",
     "shell.execute_reply": "2023-05-01T05:19:52.088260Z"
    },
    "papermill": {
     "duration": 0.040864,
     "end_time": "2023-05-01T05:19:52.092380",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.051516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imgId_eId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20057f34d_0</th>\n",
       "      <td>0.058347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20057f34d_1</th>\n",
       "      <td>0.081329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20057f34d_2</th>\n",
       "      <td>-0.042682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20057f34d_3</th>\n",
       "      <td>0.033359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20057f34d_4</th>\n",
       "      <td>0.017850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  val\n",
       "imgId_eId            \n",
       "20057f34d_0  0.058347\n",
       "20057f34d_1  0.081329\n",
       "20057f34d_2 -0.042682\n",
       "20057f34d_3  0.033359\n",
       "20057f34d_4  0.017850"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c381aac",
   "metadata": {
    "papermill": {
     "duration": 0.008581,
     "end_time": "2023-05-01T05:19:52.110071",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.101490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ground Truth\n",
    "Actual prompts used for the images  \n",
    "NOTE: This file will not be available for the notebook re-run. References to it will create notebook failures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4d442",
   "metadata": {
    "papermill": {
     "duration": 0.00845,
     "end_time": "2023-05-01T05:19:52.127275",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.118825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The Sample Submission contains correct embeddings (for the example images)\n",
    "The sample_submission.csv file on the Data page has the correct imbeddings for the prompts listed in the prompts.csv file. This is so you can test whether you are calculating embeddings correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51eef39b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:52.147310Z",
     "iopub.status.busy": "2023-05-01T05:19:52.146856Z",
     "iopub.status.idle": "2023-05-01T05:19:52.152804Z",
     "shell.execute_reply": "2023-05-01T05:19:52.151484Z"
    },
    "papermill": {
     "duration": 0.018863,
     "end_time": "2023-05-01T05:19:52.155398",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.136535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sample_submission = pd.read_csv(comp_path / 'sample_submission.csv', index_col='imgId_eId')\n",
    "#sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a124b8ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:52.175829Z",
     "iopub.status.busy": "2023-05-01T05:19:52.174503Z",
     "iopub.status.idle": "2023-05-01T05:19:52.179347Z",
     "shell.execute_reply": "2023-05-01T05:19:52.178466Z"
    },
    "papermill": {
     "duration": 0.017464,
     "end_time": "2023-05-01T05:19:52.181672",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.164208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assert (sorted(imgId_eId) == sorted(sample_submission.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83bbe3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:52.202888Z",
     "iopub.status.busy": "2023-05-01T05:19:52.202213Z",
     "iopub.status.idle": "2023-05-01T05:19:52.206133Z",
     "shell.execute_reply": "2023-05-01T05:19:52.205231Z"
    },
    "papermill": {
     "duration": 0.01736,
     "end_time": "2023-05-01T05:19:52.208437",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.191077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompts = pd.read_csv(comp_path / 'prompts.csv', index_col='imgId')\n",
    "#prompts.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b53450b",
   "metadata": {
    "papermill": {
     "duration": 0.008424,
     "end_time": "2023-05-01T05:19:52.225684",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.217260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Compare calculated embeddings with ground truth (within tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e16d4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:52.245723Z",
     "iopub.status.busy": "2023-05-01T05:19:52.245014Z",
     "iopub.status.idle": "2023-05-01T05:19:52.249365Z",
     "shell.execute_reply": "2023-05-01T05:19:52.248512Z"
    },
    "papermill": {
     "duration": 0.017145,
     "end_time": "2023-05-01T05:19:52.251644",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.234499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompt_embeddings = st_model.encode(prompts['prompt']).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b547067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:52.271749Z",
     "iopub.status.busy": "2023-05-01T05:19:52.270964Z",
     "iopub.status.idle": "2023-05-01T05:19:52.275905Z",
     "shell.execute_reply": "2023-05-01T05:19:52.274851Z"
    },
    "papermill": {
     "duration": 0.017959,
     "end_time": "2023-05-01T05:19:52.278527",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.260568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assert np.all(np.isclose(sample_submission['val'].values, prompt_embeddings, atol=1e-07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f283748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:19:52.298484Z",
     "iopub.status.busy": "2023-05-01T05:19:52.298027Z",
     "iopub.status.idle": "2023-05-01T05:19:52.313107Z",
     "shell.execute_reply": "2023-05-01T05:19:52.311803Z"
    },
    "papermill": {
     "duration": 0.028459,
     "end_time": "2023-05-01T05:19:52.315985",
     "exception": false,
     "start_time": "2023-05-01T05:19:52.287526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 110.806978,
   "end_time": "2023-05-01T05:19:55.873312",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-01T05:18:05.066334",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "071d3151c73c46f487acfcecaea8ea12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d8a3f2e21bd64fd38cb303936fb081f8",
       "placeholder": "​",
       "style": "IPY_MODEL_a672fdf2075943968e92a79efd8521fb",
       "value": "Batches: 100%"
      }
     },
     "0b6c7d2259fa4de8833faf0541b471f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "129078c5e4d345cdb3d3c5899621f7ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "164c777069f94ae1bb9a2ab1bcf282fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "491d8fc02ea7430a82a0036356fefb1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9727f1dc23af468b931cc8ba16928cca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_129078c5e4d345cdb3d3c5899621f7ba",
       "placeholder": "​",
       "style": "IPY_MODEL_0b6c7d2259fa4de8833faf0541b471f1",
       "value": " 1/1 [00:00&lt;00:00, 12.77it/s]"
      }
     },
     "98a254c1406f422eac3e82fa127ba290": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_491d8fc02ea7430a82a0036356fefb1f",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_164c777069f94ae1bb9a2ab1bcf282fd",
       "value": 1.0
      }
     },
     "a672fdf2075943968e92a79efd8521fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b3b7793b3d3c48a3b5dfe84eeed29b84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_071d3151c73c46f487acfcecaea8ea12",
        "IPY_MODEL_98a254c1406f422eac3e82fa127ba290",
        "IPY_MODEL_9727f1dc23af468b931cc8ba16928cca"
       ],
       "layout": "IPY_MODEL_cd6e296a0a02450181422bf0b4859f15"
      }
     },
     "cd6e296a0a02450181422bf0b4859f15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8a3f2e21bd64fd38cb303936fb081f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
